# fluentd/conf/fluent.conf
<source>
  @type forward
  port 24224
  @log_level info
</source>

<source >
  @type http_healthcheck
  port 9880
  bind 0.0.0.0
</source>

<filter *.efk.**>
  @type parser
  format json
  key_name log
  reserve_data false
  emit_invalid_record_to_error false                                                                                  
</filter>

<match *.efk.**>
  @type copy
  <store>
      @type elasticsearch_dynamic

      #Server settings
      host elasticsearch-svc
      port 9200
      scheme http
      ssl_verify false
      user elastic
      password SP33dMy$QL

      #Index and format settings
      
      logstash_dateformat %Y%m
      logstash_format true
      logstash_prefix  ${record['es_index'] || 'fluentd'} 
      include_tag_key true
      
      # HTTP request settings per threat etc
      request_timeout 15s
      reload_connections false
      reconnect_on_error true
      reload_on_failure true
      num_threads 8

  # # Buffer is used fo many chunk data incomming
  <buffer>
     
     flush_thread_count "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_FLUSH_THREAD_COUNT'] || '8'}"
     flush_interval "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_FLUSH_INTERVAL'] || '5s'}"
     chunk_limit_size "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_CHUNK_LIMIT_SIZE'] || '10M'}"
     queue_limit_length "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_QUEUE_LIMIT_LENGTH'] || '32'}"
     retry_max_interval "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_RETRY_MAX_INTERVAL'] || '30'}"
     retry_forever true

  </buffer>
      
  </store>
   <store>
   @type stdout
  </store>
</match>